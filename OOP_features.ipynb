{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import io\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "dataset_path = f\"dataset.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "dataset.head(), dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid image links\n",
    "valid_image_links = [url for url in dataset['image_links'].dropna().unique() if url.startswith(\"http\")]\n",
    "\n",
    "valid_image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract Image Embeddings and Cache Locally using ResNet\n",
    "EMBEDDING_CACHE = \"embeddings_cache.pkl\"\n",
    "embeddings_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation pipeline for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove the classification layer\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(EMBEDDING_CACHE, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached embeddings if available\n",
    "if os.path.exists(EMBEDDING_CACHE) and os.path.getsize(EMBEDDING_CACHE) > 0:\n",
    "    with open(EMBEDDING_CACHE, \"rb\") as f:\n",
    "        embeddings_cache = pickle.load(f)\n",
    "    print(\"Embeddings cache loaded successfully.\")\n",
    "else:\n",
    "    print(\"No cache!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding_from_url(image_url):\n",
    "    # Check cache first\n",
    "    if image_url in embeddings_cache:\n",
    "        return embeddings_cache[image_url]\n",
    "    \n",
    "    try:\n",
    "        # Use requests.get() without stream to ensure full content is downloaded\n",
    "        response = requests.get(image_url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad HTTP responses\n",
    "        \n",
    "        # Use BytesIO to create a file-like object\n",
    "        image_data = io.BytesIO(response.content)\n",
    "        \n",
    "        # Open image with explicit error handling\n",
    "        try:\n",
    "            image = Image.open(image_data).convert(\"RGB\")\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"Could not identify image from {image_url}\")\n",
    "            return None\n",
    "        \n",
    "        # Apply transformations\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embedding = model(image).squeeze().numpy()\n",
    "        \n",
    "        # Cache the embedding\n",
    "        embeddings_cache[image_url] = embedding\n",
    "        return embedding\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching image from {image_url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing {image_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cache after each run\n",
    "def save_embeddings_cache():\n",
    "    with open(EMBEDDING_CACHE, \"wb\") as f:\n",
    "        pickle.dump(embeddings_cache, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_index = 0\n",
    "progress_length = len(valid_image_links)\n",
    "\n",
    "# for url in valid_image_links:\n",
    "#     extract_embedding_from_url(url)\n",
    "#     print(f\"{progress_index}/{progress_length}: extracting embeddings from {url}\")\n",
    "#     progress_index += 1\n",
    "\n",
    "def extract_embedding_multithread(image_links, max_thread = 10):\n",
    "    with ThreadPoolExecutor(max_workers=max_thread) as executor:\n",
    "        results = list(tqdm(\n",
    "            executor.map(extract_embedding_from_url, image_links),\n",
    "            total = len(image_links),\n",
    "            desc = \"Extracting embeddings\"\n",
    "        ))\n",
    "    total_images = len(image_links)\n",
    "    successful_embeddings = sum(1 for result in results if result is not None)\n",
    "    failed_count = total_images - successful_embeddings\n",
    "    print(f\"Extraction complete. \"\n",
    "                 f\"Total images: {total_images}, \"\n",
    "                 f\"Successful: {successful_embeddings}, \"\n",
    "                 f\"Failed: {failed_count}\")\n",
    "\n",
    "extract_embedding_multithread(valid_image_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = random.choice(valid_image_links)\n",
    "# print(str(res))\n",
    "# len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Image Similarity Matching Logic\n",
    "\n",
    "# Function to find similar images from the cache\n",
    "# Args:\n",
    "#   query_image_url (str): URL of the query image to compare.\n",
    "#   image_urls (list, optional): List of additional image URLs (not currently used).\n",
    "#   top_k (int): Number of top similar images to retrieve. Default is 5.\n",
    "# Returns:\n",
    "#   list: A list of top_k similar image URLs from the cache.\n",
    "\n",
    "def find_similar_images_from_urls(query_image_url, image_urls=None, top_k=5):\n",
    "    # Step 2.1: Extract embedding for the query image\n",
    "    print(\"Extracting query image embedding...\")\n",
    "    query_embedding = extract_embedding_from_url(query_image_url)\n",
    "    if query_embedding is None:  # Handle invalid or failed extraction\n",
    "        return []\n",
    "\n",
    "    embeddings = []  # List to store cached embeddings\n",
    "    valid_image_urls = []  # List to store corresponding image URLs\n",
    "\n",
    "    # Step 2.2: Load embeddings from the cache\n",
    "    print(\"Loading embeddings from cache...\")\n",
    "    for url, embedding in embeddings_cache.items():\n",
    "        embeddings.append(embedding)  # Append embedding to the list\n",
    "        valid_image_urls.append(url)  # Append corresponding URL\n",
    "\n",
    "    # Step 2.3: Check if the cache is empty\n",
    "    if not embeddings:\n",
    "        print(\"No embeddings available in the cache.\")\n",
    "        return []\n",
    "\n",
    "    # Step 2.4: Compute cosine similarity between the query embedding and cached embeddings\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    print(similarities.shape)\n",
    "\n",
    "    # Step 2.5: Sort similarities and retrieve indices of the top_k most similar embeddings\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]  # Sort in descending order\n",
    "    print(\"\\nTop Similar Images:\")\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        print(f\"{i}. Image: {valid_image_links[idx]}\")\n",
    "        print(f\"   Similarity Score: {similarities[idx]:.4f}\")\n",
    "\n",
    "    # Step 2.6: Save the updated cache (if any updates were made elsewhere)\n",
    "    save_embeddings_cache()\n",
    "\n",
    "res = random.choice(valid_image_links)\n",
    "print(res)\n",
    "find_similar_images_from_urls(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Build Similarity Search Engines\n",
    "# # Build FAISS index\n",
    "# def build_faiss_index(embeddings):\n",
    "#     dimension = embeddings[0].shape[0]\n",
    "#     index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
    "#     faiss_embeddings = np.vstack(embeddings)\n",
    "#     index.add(faiss_embeddings)\n",
    "#     return index\n",
    "\n",
    "# # Build HNSW index\n",
    "# def build_hnsw_index(embeddings, space=\"cosine\"):\n",
    "#     dimension = embeddings[0].shape[0]\n",
    "#     index = hnswlib.Index(space=space, dim=dimension)\n",
    "#     index.init_index(max_elements=len(embeddings), ef_construction=200, M=16)\n",
    "#     for i, embedding in enumerate(embeddings):\n",
    "#         index.add_items(embedding, i)\n",
    "#     index.set_ef(50)  # Controls recall quality at query time\n",
    "#     return index\n",
    "\n",
    "# Function to find similar images using cosine similarity\n",
    "def find_similar_cosine(query_embedding, embeddings, top_k=5):\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    return top_indices, similarities\n",
    "\n",
    "# Step 3: Find Similar Images from Cache\n",
    "def find_similar_images(query_image_url, top_k=20):\n",
    "    print(\"Extracting query image embedding...\")\n",
    "    query_embedding = extract_embedding_from_url(query_image_url)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "\n",
    "    embeddings = []\n",
    "    valid_image_urls = []\n",
    "\n",
    "    print(\"Loading embeddings from cache...\")\n",
    "    for url, embedding in embeddings_cache.items():\n",
    "        embeddings.append(embedding)\n",
    "        valid_image_urls.append(url)\n",
    "\n",
    "    if not embeddings:\n",
    "        print(\"No embeddings available in the cache.\")\n",
    "        return []\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    query_embedding = np.array(query_embedding)\n",
    "\n",
    "    top_indices, similarities = find_similar_cosine(query_embedding, embeddings, top_k)\n",
    "    # if method == \"cosine\":\n",
    "    #     # Cosine Similarity Search\n",
    "    # elif method == \"faiss\":\n",
    "    #     # FAISS Search\n",
    "    #     faiss_index = build_faiss_index(embeddings)\n",
    "    #     _, top_indices = faiss_index.search(np.expand_dims(query_embedding, axis=0), top_k)\n",
    "    #     top_indices = top_indices[0]\n",
    "    #     similarities = None\n",
    "    # elif method == \"hnsw\":\n",
    "    #     # HNSW Search\n",
    "    #     hnsw_index = build_hnsw_index(embeddings)\n",
    "    #     labels, _ = hnsw_index.knn_query(query_embedding, k=top_k)\n",
    "    #     top_indices = labels[0]\n",
    "    #     similarities = None\n",
    "    # else:\n",
    "    #     raise ValueError(\"Invalid method. Choose from ['cosine', 'faiss', 'hnsw']\")\n",
    "\n",
    "    # save_embeddings_cache()  # Save updated cache\n",
    "\n",
    "    print(\"Top similar images:\")\n",
    "    \n",
    "    for i, index in enumerate(top_indices, 1):\n",
    "        print(f\"{index}.{similarities[index]}: {valid_image_urls[index]}\")\n",
    "    return [valid_image_urls[i] for i in top_indices]\n",
    "\n",
    "# Example usage\n",
    "query_image_url = random.choice(valid_image_links) # Replace with a query image URL\n",
    "query_image_url = \"https://thumbs.dreamstime.com/b/beach-ball-12760024.jpg\"\n",
    "print(query_image_url)\n",
    "similar_images = find_similar_images(query_image_url)  # Options: \"cosine\", \"faiss\", \"hnsw\"\n",
    "print(\"Top similar images:\")\n",
    "for img_url in similar_images:\n",
    "    print(img_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Load and Preprocess Data\n",
    "# ============================\n",
    "# Load the dataset (replace with your file path)\n",
    "\n",
    "# Combine text fields for embedding\n",
    "dataset['combined_text'] = dataset['category_1'] + \" \" + dataset['category_2'] + \" \" + dataset['category_3'] + \" \" + dataset['title']\n",
    "\n",
    "# =============================\n",
    "# 2. Text Embedding Generation\n",
    "# =============================\n",
    "# Load pre-trained Sentence Transformer model\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "TEXT_EMBEDDINGS_CACHE = \"text_embeddings_cache.pkl\"\n",
    "text_embeddings_cache = {}\n",
    "text_datas = dataset['combined_text'].tolist()\n",
    "\n",
    "# Generate text embeddings for the dataset\n",
    "def generate_text_embeddings(text_data):\n",
    "    if text_data in text_embeddings_cache:\n",
    "        return text_embeddings_cache[text_data]\n",
    "    try:\n",
    "        text_embedding = text_model.encode(text_data, convert_to_tensor=True)\n",
    "        print(\"Generating text embeddings...\")\n",
    "        text_embeddings_cache[text_datas] = text_embedding\n",
    "        return text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def extract_text_embeddings_multithread(text_datas, max_thread = 10):\n",
    "    with ThreadPoolExecutor(max_workers=max_thread) as executor:\n",
    "        results = list(tqdm(\n",
    "            executor.map(generate_text_embeddings, text_datas),\n",
    "            total = len(text_datas),\n",
    "            desc = \"Extracting text embeddings\"\n",
    "        ))\n",
    "    total_images = len(image_links)\n",
    "    successful_embeddings = sum(1 for result in results if result is not None)\n",
    "    failed_count = total_images - successful_embeddings\n",
    "    print(f\"Extraction complete. \"\n",
    "                 f\"Total images: {total_images}, \"\n",
    "                 f\"Successful: {successful_embeddings}, \"\n",
    "                 f\"Failed: {failed_count}\")\n",
    "\n",
    "def save_text_embedding_cache():\n",
    "    with open(TEXT_EMBEDDINGS_CACHE, \"wb\") as f:\n",
    "        pickle.dump(text_embeddings_cache, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
